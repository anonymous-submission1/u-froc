from functools import partial

import torch
import dpipe.commands as commands
from dpipe.config import if_missing, lock_dir, run
from dpipe.im.metrics import aggregate_metric, dice_score
from dpipe.layout import Flat
from dpipe.train import train, Checkpoints, Policy, TimeProfiler, TBLogger
from dpipe.train.validator import compute_metrics
from dpipe.torch import save_model_state, load_model_state, train_step

from ufroc.im.metric import froc_records
from ufroc.commands import evaluate_individual_metrics_probably_with_froc
from ufroc.utils import fix_seed


# ### 1. PATHS ###

log_path = 'train_logs'
saved_model_path = 'model.pth'
saved_optim_path = 'optimizer.pth'
test_predictions_path = 'test_predictions'
checkpoints_path = 'checkpoints'

# ### 2. BUILD EXPERIMENT ###

layout = Flat(split)
train_ids = layout.get_ids('train')
test_ids = layout.get_ids('test')
val_ids = layout.get_ids('val')

# ### 3. TRAIN MODEL ###

n_chans_in = 1
n_chans_out = 1

# 3.1 validation
dice_metric = lambda x, y: dice_score(x > 0.5, y > 0.5)
val_metrics = {'dice_score': partial(aggregate_metric, metric=dice_metric), }

validate_step = partial(compute_metrics, predict=predict, load_x=load_x, load_y=load_y,
                        ids=val_ids, metrics=val_metrics)

# 3.2 train
logger = TBLogger(log_path=log_path)

train_kwargs = dict(lr=lr, architecture=architecture, optimizer=optimizer, criterion=criterion)

checkpoints = Checkpoints(checkpoints_path, {
    **{k: v for k, v in train_kwargs.items() if isinstance(v, Policy)},
    saved_model_path: architecture, saved_optim_path: optimizer
})

amp = True
scaler = torch.cuda.amp.GradScaler()

train_model = train(
    train_step=partial(train_step, scaler=scaler),
    batch_iter=batch_iter,
    n_epochs=n_epochs,
    logger=logger,
    time=TimeProfiler(logger.logger),
    checkpoints=checkpoints,
    validate=validate_step,
    **train_kwargs
)

# ### 4. RUN EXPERIMENT ###

load_x = dataset.load_image
load_y = dataset.load_segm

predict_to_dir = partial(commands.predict, ids=test_ids, load_x=load_x, predict_fn=predict_logit)

froc_metric = lambda x, y, y_logit: froc_records(x > 0.5, y > 0.5, y_logit)
final_metrics = {'dice_score': dice_metric, 'froc': froc_metric, }

evaluate_individual_metrics = partial(
    evaluate_individual_metrics_probably_with_froc,
    load_y=load_y,
    metrics=final_metrics,
    logits_path=test_predictions_path,
)

seed = 0xBadCafe
device = 'cuda'

# TODO: move to `populate`
# resource-manager execute sequence below:
# ##########################################
run_experiment = run(
    fix_seed(seed=seed),
    lock_dir(),
    architecture.to(device),
    if_missing(lambda p: [train_model, save_model_state(architecture, p)], saved_model_path),
    load_model_state(architecture, saved_model_path),
    if_missing(predict_to_dir, output_path=test_predictions_path),
    if_missing(evaluate_individual_metrics, results_path='test_metrics'),
)
# ##########################################
